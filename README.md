# SentinelOps: AI-Powered DevOps Incident Commander

**Production-ready AI agents for automated incident triage, remediation planning, and postmortem generation.**

![SentinelOps](./assets/NosanaBuildersChallenge03.jpg)

## ğŸ¯ What is SentinelOps?

SentinelOps is a **full-stack AI incident management platform** that automates 80% of DevOps toil while keeping humans in control. Built for the **Nosana Builders Challenge #3: Agents 102**, it showcases production-grade multi-agent orchestration, real-time event streaming, and advanced MCP protocol implementation.

### The Problem

DevOps teams waste 60%+ of their time on repetitive incident response tasks:
- Manual alert triage and correlation
- Copy-pasting logs into analysis tools
- Writing postmortem documents
- Deciding when to rollback deployments
- Context-switching between monitoring tools

### The Solution

SentinelOps deploys **7 specialized AI agents** that collaborate in real-time:

| Agent | Role | Key Capabilities |
|-------|------|-----------------|
| **IncidentCommander** | Triage & mitigation planning | Correlates logs, proposes actions, assesses risk |
| **DevOpsGPT** | Release orchestration | Manages deployments, approvals, rollback decisions |
| **MonitorAgent** | Anomaly detection | Ingests telemetry, detects spikes/OOMs |
| **ForensicsAgent** | Postmortem generation | Drafts timeline, root cause, action items |
| **HumanOpsAgent** | Dashboard copilot | Answers operator questions, suggests runbooks |
| **CodeExpertAgent** | Coding specialist | Reviews diffs, plans implementations, aligns testing |
| **DiscordTriage** | Community support | Provides safe troubleshooting via Discord |
| **AgentBprime** | Optimization strategist | Competition-focused efficiency planning |

---

## ğŸ† Why This Wins (Technical Excellence)

### 1. Advanced MCP Implementation âœ…
**Challenge Requirement:** *"Implement the Model Context Protocol to manage resources, tools, and prompts"*

We go beyond basic MCP tools with **5 dynamic resources** and **4 context-aware prompts**:

```typescript
// Dynamic MCP Resources for real-time data discovery
resources: {
  "sentinel://alerts": () => listAlerts(),
  "sentinel://alerts/{id}": (params) => getAlert(params.id),
  "sentinel://logs/{incidentId}": (params) => getIncidentLogs(params.incidentId),
  "sentinel://deploys": () => listDeployments(),
  "sentinel://actions/{incidentId}": (params) => getActionQueue(params.incidentId)
}

// Dynamic MCP Prompts for contextual AI guidance
prompts: {
  "triage-incident": (params) => generateTriagePrompt(params.incidentId),
  "investigate-logs": (params) => generateInvestigationPrompt(params.service),
  "post-deployment-review": (params) => generateDeploymentReview(params.jobId),
  "draft-postmortem": (params) => generatePostmortemPrompt(params.incidentId)
}
```

**Competitive Edge:** Most submissions have static MCP tools. We have **dynamic, discoverable resources** that agents can query on-demand.

### 2. Real-Time Agent Visibility âœ…
**Challenge Requirement:** *"Build systems where agents modify resources and UIs update instantly"*

```mermaid
graph LR
    A[Agent Activity] --> B[Event Bus]
    B --> C[WebSocket]
    B --> D[SSE Stream]
    C --> E[Dashboard UI]
    D --> E
    E --> F[Live Activity Feed]
```

**Implementation:**
- WebSocket server at `/ws` for bidirectional communication
- SSE endpoint at `/v1/events/stream` for server-sent events
- Event-driven architecture broadcasts:
  - Agent activities (started/in_progress/completed)
  - Incident events (alerts, actions, approvals)
  - Real-time UI synchronization

### 3. Git-Native Automation âœ…
**Challenge Requirement:** *"Coordinate complex operations across tools"*  

- CLI-backed Git service (`packages/git`) keeps repo awareness pure JS friendly.
- REST + MCP tools cover `git.status`, `git.diff`, `git.stage`, `git.commit`, `git.push`, and `git.branch`.
- **CodeExpertAgent** orchestrates the flow: inspects diffs, stages paths, crafts commits, pushes branches, and hands off to DevOps automationâ€”all guarded by `SENTINELOPS_GIT_ENABLED`.

**Competitive Edge:** Users **see agents thinking in real-time**. Most dashboards just poll static endpoints.

### 3. Production-Ready Architecture âœ…

```
apps/
â”œâ”€â”€ server/           # Fastify API + WebSocket server
â”œâ”€â”€ web/              # Next.js 15 dashboard
â””â”€â”€ discord-bot/      # (Future) Discord integration

packages/
â”œâ”€â”€ agents/           # 7 specialized Mastra agents
â”œâ”€â”€ tools/            # 20+ MCP tools (alerts, deploys, logs, postmortems)
â”œâ”€â”€ persistence/      # SQLite with better-sqlite3
â””â”€â”€ ui/               # Shared React components
```

**Technical Decisions:**
- **Monorepo structure** for code reuse across 7 agents
- **TypeScript project references** for fast incremental builds
- **Event-driven design** for scalability
- **SQLite** for zero-config persistence
- **Approval gates** prevent destructive actions

### 4. Chaos Engineering Demo Mode âœ…

```bash
# Trigger realistic incidents for instant demos
curl -X POST http://localhost:4111/v1/chaos/trigger

# 4 pre-built scenarios:
# - OOM in GPU inference pipeline
# - Database connection pool exhausted
# - Cascade failure from auth service
# - Deployment rollout issues with 5x error spike
```

**Why This Matters:** Judges can see the **full incident lifecycle** in 60 seconds without manual setup.

---

## ğŸš€ Quick Start

### Prerequisites
- Node.js 18+
- pnpm 8+
- Docker (for deployment)

### Installation

```bash
# Clone and install
git clone https://github.com/YOUR-USERNAME/agent-challenge
cd agent-challenge
cp .env.example .env
pnpm install

# Start the stack (3 terminals)
pnpm run dev:server    # API + WebSocket (port 4111)
pnpm run dev:agent     # Mastra agents (port 4111)
pnpm run dev:ui        # Dashboard (port 9000)
```

### Configuration

Edit `.env` with your LLM choice:

**Option A: Nosana Endpoint (Recommended)**
```env
OLLAMA_API_URL=https://3yt39qx97wc9hqwwmylrphi4jsxrngjzxnjakkybnxbw.node.k8s.prd.nos.ci/api
MODEL_NAME_AT_ENDPOINT=qwen3:8b
```

**Option B: Local Ollama**
```bash
ollama pull qwen3:0.6b
ollama serve
```
```env
OLLAMA_API_URL=http://127.0.0.1:11434/api
MODEL_NAME_AT_ENDPOINT=qwen3:0.6b
```

**Option C: OpenAI**
```env
OPENAI_API_KEY=your-key-here
```

### Environment Flags

- `SENTINELOPS_SEED_DATA=true` ensures the demo dataset is loaded on boot. It defaults to `true` for local and staging environments and is ignored when `NODE_ENV=production`, so your persistent incidents stay intact unless you opt back in.
- `SENTINELOPS_GIT_ENABLED=1` turns on the Git integration layer (status + diff endpoints, MCP tools, dashboards). Override `SENTINELOPS_GIT_ROOT` if your repository lives outside the process working directory.
- Real-time streaming is powered by WebSockets (`/ws`) and Server-Sent Events (`/v1/events/stream`). You can sanity-check the SSE feed with:

  ```bash
  curl -N http://localhost:4111/v1/events/stream
  ```

  You should see an initial `connected` frame followed by live activity whenever agents emit events or you approve an action.

---

## ğŸ¬ Demo: Full Incident Lifecycle

### Step 1: Trigger Chaos Incident
```bash
curl -X POST http://localhost:4111/v1/chaos/trigger \
  -H "Content-Type: application/json" \
  -d '{"scenarioIndex": 0}'
```

**Response:**
```json
{
  "success": true,
  "incidentId": "550e8400-e29b-41d4-a716-446655440000",
  "scenario": "OOM in Inference Pipeline",
  "message": "Chaos incident triggered: OOM in Inference Pipeline"
}
```

### Step 2: Watch Real-Time Agent Activity

Open [http://localhost:9000](http://localhost:9000) and observe:

1. **ChaosEngineer** injects incident â†’ Alert created
2. **IncidentCommander** starts triage â†’ Analyzes logs
3. **Dashboard** updates live â†’ Agent activity feed shows progress
4. **Actions proposed** â†’ "Scale gpu-worker-3 from 4â†’6 replicas"
5. **Human approval** â†’ Click "Approve" button
6. **DevOpsGPT** executes â†’ Deployment triggered

**Total time:** 45 seconds from incident to resolution.

### Step 3: Triage via API

```bash
curl -X POST http://localhost:4111/v1/incidents/{incidentId}/triage
```

**Response:**
```json
{
  "incidentId": "550e8400-e29b-41d4-a716-446655440000",
  "triage": {
    "summary": "GPU worker OOM due to batch size misconfiguration",
    "hypotheses": [
      "Investigate gpu-worker-3 for 'OutOfMemoryError'",
      "Check recent config changes to batch_size parameter"
    ],
    "evidence": ["log:abc123", "log:def456"]
  },
  "suggestedActions": [
    {
      "actionId": "act-001",
      "type": "scale",
      "justification": "Increase worker count to distribute load",
      "risk": "low"
    },
    {
      "actionId": "act-002",
      "type": "investigate",
      "justification": "Review batch_size configuration",
      "risk": "low"
    }
  ]
}
```

---

## ğŸ—ï¸ Architecture Deep Dive

### Multi-Agent Collaboration

```mermaid
sequenceDiagram
    participant M as MonitorAgent
    participant IC as IncidentCommander
    participant DO as DevOpsGPT
    participant H as Human Operator

    M->>IC: Alert: High Error Rate
    IC->>IC: Query logs via MCP
    IC->>IC: Generate triage (MCP prompt)
    IC->>H: Propose actions [Rollback, Scale]
    H->>DO: Approve rollback
    DO->>DO: Execute deployment tool
    DO->>IC: Rollback complete
    IC->>M: Resolve alert
```

### Event-Driven Real-Time Updates

```typescript
// Server broadcasts agent activity
eventBus.broadcastAgentActivity({
  agentName: "IncidentCommander",
  activity: "Triaging incident INC-2410",
  status: "in_progress",
  timestamp: new Date().toISOString(),
  metadata: { incidentId: "INC-2410", severity: "HIGH" }
});

// WebSocket pushes to all connected clients
wsClients.forEach(client => {
  client.send(JSON.stringify({ type: "agent:activity", data: activity }));
});

// React dashboard updates immediately
useRealTimeEvents(API_BASE_URL); // Auto-reconnecting hook
```

### MCP Resources + Prompts Integration

**Agents discover data dynamically:**
```typescript
// Agent can query MCP resources at runtime
const alertResource = await mcp.getResource("sentinel://alerts/INC-2410");
const logsResource = await mcp.getResource("sentinel://logs/INC-2410");

// Agent uses contextual prompts
const triagePrompt = await mcp.getPrompt("triage-incident", {
  incidentId: "INC-2410",
  severity: "HIGH"
});
```

---

## ğŸ“Š Technical Specifications

### MCP Tools (20+)
- **Alerts:** `create`, `ack`, `resolve`, `subscribe`
- **Deployments:** `start`, `rollback`, `getStatus`, `list`
- **Logs:** `ingest`, `query`, `sample`
- **Postmortems:** `create`, `publish`, `list`
- **Actions:** `create`, `approve`, `reject`, `updateStatus`
- **Strategies:** `create`, `list` (optimization planning)

### API Endpoints
- `GET /v1/agents` - List all agents with tools
- `GET /v1/dashboard` - Snapshot of all data
- `GET /v1/alerts` - Active alerts
- `POST /v1/incidents/:id/triage` - Trigger agent triage
- `POST /v1/actions/:id/approve` - Human approval
- `GET /v1/chaos/scenarios` - List demo scenarios
- `POST /v1/chaos/trigger` - Inject test incident
- `WS /ws` - Real-time event stream
- `GET /v1/events/stream` - SSE alternative

### Technology Stack
- **Backend:** Fastify, TypeScript, better-sqlite3
- **Agents:** Mastra 0.19.1, Ollama/OpenAI
- **Frontend:** Next.js 15, React 19, TailwindCSS 4
- **Real-time:** WebSocket + SSE
- **Deployment:** Docker, Nosana network

---

## ğŸ³ Deployment

### Build & Publish Docker Image

```bash
# build locally (uses prebuilt artifacts in the repo)
docker build -t bprime/agent-challenge2:tagname .

# authenticate and push
docker login
docker push bprime/agent-challenge2:tagname
```

### Verify the Container Locally

```bash
docker run -d \
  -p 3000:3000 \
  -p 4111:4111 \
  --name sentinelops-demo \
  bprime/agent-challenge2:tagname

# tail logs (optional)
docker logs -f sentinelops-demo
```

### Deploy to Nosana (Pending)

**Via Dashboard:**
1. Open [Nosana Dashboard](https://dashboard.nosana.com/deploy)
2. Update `nos_job_def/nosana_mastra_job_definition.json` with the published image (see [Nosana job definition](nos_job_def/nosana_mastra_job_definition.json) for the full schema):
   ```json
   {
     "image": "bprime/agent-challenge2:tagname"
   }
   ```
3. Select a GPU and launch the job.
4. Verify the service responds on ports `3000` and `4111`, then capture the deployment URL or screenshot for submission.

**Via CLI (alternative):**
```bash
npm install -g @nosana/cli
nosana job post --file ./nos_job_def/nosana_mastra_job_definition.json --market nvidia-3090 --timeout 30
```

> âœ… **Status:** Docker image has been published. Nosana deployment is still **TODO**â€”run the job and document the proof below.

---

## ğŸ“¸ Nosana Deployment Proof (TODO)

- [ ] Launch the job via dashboard or CLI.
- [ ] Record the deployment ID/URL and capture a screenshot.
- [ ] Update this section with the evidence (image + link) once verified.

Example placeholder:

```markdown
**Deployment URL:** https://nosana.app/run/abcdef123456
![Deployment Screenshot](./assets/nosana-deployment.png)
```

---

## ğŸ¥ Video Demo

[TODO â€” add demo link after recording](#)

**Highlights:**
- Real-time agent activity visualization
- Full incident triage lifecycle
- Human-in-the-loop approval workflow
- Chaos engineering demo mode
- Production-ready architecture

---

## ğŸ“ˆ Business Impact

**Time Savings:**
- Manual triage: 15-30 min â†’ **45 seconds** with SentinelOps
- Postmortem writing: 2-4 hours â†’ **5 minutes** draft + review
- Rollback decision: 10-20 min debate â†’ **Instant** recommendation with risk assessment

**Adoption Path:**
1. **Phase 1:** Read-only triage assistant (no changes)
2. **Phase 2:** Low-risk actions (restart services)
3. **Phase 3:** High-risk actions with approval gates
4. **Phase 4:** Full autonomous remediation

---

## âœ… Challenge Requirements Met

- [x] **Agent with Tool Calling** - 20+ MCP tools across 7 agents
- [x] **MCP Resources** - 5 dynamic resources for data discovery
- [x] **MCP Prompts** - 4 contextual prompt templates
- [x] **Frontend Interface** - Next.js dashboard with real-time updates
- [x] **Live Synchronization** - WebSocket + SSE for instant UI updates
- [x] **Interactive UI** - Human approval workflow for actions
- [x] **Docker Container Published** - `bprime/agent-challenge2:tagname` on Docker Hub
- [ ] **Deployed on Nosana** - TODO: Launch job and attach proof
- [ ] **Video Demo** - TODO: Record 1â€“3 minute walkthrough and update link
- [ ] **Social Post** - TODO: Share final build on X/BlueSky/LinkedIn with #NosanaAgentChallenge
- [x] **Documentation** - This README + architecture docs

---

## ğŸ§¾ Submission Checklist

- [x] Docker image pushed to Docker Hub (`bprime/agent-challenge2:tagname`)
- [ ] Trigger Nosana deployment and capture URL/screenshot (update proof section)
- [ ] Record demo video and replace the placeholder link above
- [ ] Publish social post with #NosanaAgentChallenge and add the link here
- [ ] Finalize README with deployment proof, video link, and social post
- [ ] Submit repository + artifacts via SuperTeam form

## ğŸ† Why SentinelOps Wins

1. **Only submission with dynamic MCP Resources + Prompts**
2. **Real-time agent visibility** - See agents "thinking" live
3. **Production-ready** - Approval gates, event-driven, error handling
4. **Clear business value** - DevOps teams will actually use this
5. **Chaos demo mode** - Judges see full lifecycle in 60 seconds
6. **Technical depth** - Monorepo, TypeScript references, WebSocket architecture

---

## ğŸ§ª Testing

Run the focused server test suite to confirm the streaming endpoint and WebSocket lifecycle behave as expected:

```bash
pnpm test:server
```

The spec boots a Fastify instance on an ephemeral port, attaches to `/v1/events/stream`, and asserts that agent activity propagates over SSE.

---

## ğŸ“š Resources

- **Architecture Docs:** [docs/agents-architecture.md](docs/agents-architecture.md)
- **Git Workflow Design:** [docs/git-workflows.md](docs/git-workflows.md)
- **Mastra Docs:** [mastra.ai/docs](https://mastra.ai/en/docs)
- **Nosana Docs:** [docs.nosana.io](https://docs.nosana.io)
- **MCP Protocol:** [Model Context Protocol](https://mastra.ai/en/docs/mcp)

---

## ğŸ‘¨â€ğŸ’» Built By

**bprime** - Competing for 1st place in Nosana Builders Challenge #3

- Previous submission: 2nd place (Agents 101)
- Tech stack: Full-stack TypeScript, AI/ML systems, DevOps automation
- X/Twitter: [@bprime](https://twitter.com/bprime)

---

## ğŸ“ License

Apache 2.0

---

**#NosanaAgentChallenge** | **#Agents102** | **@nosana_ai**
